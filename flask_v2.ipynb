{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b096140-e17e-43b7-aab9-47c727522c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : ASCEND_HOME_PATH environment variable is not set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:301: ImportWarning: \n",
      "    *************************************************************************************************************\n",
      "    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..\n",
      "    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..\n",
      "    The backend in torch.distributed.init_process_group set to hccl now..\n",
      "    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..\n",
      "    The device parameters have been replaced with npu in the function below:\n",
      "    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty\n",
      "    *************************************************************************************************************\n",
      "    \n",
      "  warnings.warn(msg, ImportWarning)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/ma-user/.cache/huggingface/modules/transformers_modules/chatglm-6b/modeling_chatglm.py:1259: DeprecationWarning: invalid escape sequence \\?\n",
      "  [\"\\?\", \"？\"],\n",
      "Loading checkpoint shards: 100%|██████████| 8/8 [00:41<00:00,  5.23s/it]\n",
      "[W compiler_depend.ts:615] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())\n",
      "/usr/local/Ascend/ascend-toolkit/8.0.RC1/python/site-packages/tbe/tvm/contrib/ccec.py:792: DeprecationWarning: invalid escape sequence \\L\n",
      "  if not dirpath.find(\"AppData\\Local\\Temp\"):\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/classifier/transdata/transdata_classifier.py:222: DeprecationWarning: invalid escape sequence \\B\n",
      "  \"\"\"\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/vector/transdata/common/graph/transdata_graph_info.py:143: DeprecationWarning: invalid escape sequence \\c\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import os\n",
    "import torch\n",
    "import torch_npu\n",
    "from torch_npu.contrib import transfer_to_npu\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import gc\n",
    "app = Flask(__name__)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/ma-user/work/ctglm/chatglm-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"/home/ma-user/work/ctglm/chatglm-6b\", trust_remote_code=True).half().cuda()\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b973db-43e4-4c21-9bf3-755270786b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5004\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "MAX_HISTORY_LENGTH = 3\n",
    "@app.route('/posttext', methods=['POST'])\n",
    "def post_text():\n",
    "    global history\n",
    "    # 检查请求中是否有数据\n",
    "    if request.is_json:\n",
    "        # 获取 JSON 请求体中的数据\n",
    "        data = request.get_json()\n",
    "        # 假设我们期待的是一个包含 'text' 键的 JSON 对象\n",
    "        text = data.get('text', '')\n",
    "        # 处理文本或者直接返回\n",
    "        response, history = model.chat(tokenizer, text, history=history)\n",
    "        history.append((text, response))\n",
    "        if len(history) > MAX_HISTORY_LENGTH:\n",
    "            history = history[-MAX_HISTORY_LENGTH:]\n",
    "        # print(response)\n",
    "        return jsonify({\"received_text\": response})\n",
    "    else:\n",
    "        # 如果不是 JSON 数据，尝试直接从表单数据中获取文本\n",
    "        text = request.form.get('text', '')\n",
    "        return jsonify({\"received_text\": text})\n",
    "    \n",
    "    \n",
    "@app.route('/clearhistory', methods=['POST'])\n",
    "def clear_history():\n",
    "    global history\n",
    "    history = []\n",
    "    gc.collect()\n",
    "    torch.npu.empty_cache()\n",
    "    print(\"历史记录已清除，并尝试释放内存。\")\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, use_reloader=False,port=5004)\n",
    "    \n",
    "    \n",
    "# # 发送表单数据\n",
    "# curl -X POST http://localhost:5000/posttext -d \"text=这是一段文本\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065496e4-0022-4d8d-8a48-a8e6d98bdf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# def clear_history():\n",
    "#     global history\n",
    "#     history = []\n",
    "#     gc.collect()\n",
    "#     torch.npu.empty_cache()\n",
    "#     print(\"历史记录已清除，并尝试释放内存。\")\n",
    "\n",
    "\n",
    "# #clear_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
