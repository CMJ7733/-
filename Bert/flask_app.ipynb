{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbdfc46f-f40f-4422-96ca-014e2390b54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning : ASCEND_HOME_PATH environment variable is not set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:301: ImportWarning: \n",
      "    *************************************************************************************************************\n",
      "    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..\n",
      "    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..\n",
      "    The backend in torch.distributed.init_process_group set to hccl now..\n",
      "    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..\n",
      "    The device parameters have been replaced with npu in the function below:\n",
      "    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.autocast, torch.load, torch.Generator, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.nn.Module.to, torch.nn.Module.to_empty\n",
      "    *************************************************************************************************************\n",
      "    \n",
      "  warnings.warn(msg, ImportWarning)\n",
      "/home/ma-user/anaconda3/envs/MindSpore/lib/python3.9/site-packages/torch_npu/contrib/transfer_to_npu.py:260: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: since the loaded file is not a zipfile, only \"torch.device\" and \"str\" type parameters are currently supported for parameter types of map_locationIf parameter types of map_location is \"Callable[[torch.Tensor, str], torch.Tensor]\" or \"Dict[str, str]\", which is only support for zipfile,all tensors are currently loaded onto the CPU, which may introduce problems\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W compiler_depend.ts:615] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())\n",
      "/usr/local/Ascend/ascend-toolkit/8.0.RC1/python/site-packages/tbe/tvm/contrib/ccec.py:792: DeprecationWarning: invalid escape sequence \\L\n",
      "  if not dirpath.find(\"AppData\\Local\\Temp\"):\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/classifier/transdata/transdata_classifier.py:222: DeprecationWarning: invalid escape sequence \\B\n",
      "  \"\"\"\n",
      "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/dsl/unify_schedule/vector/transdata/common/graph/transdata_graph_info.py:143: DeprecationWarning: invalid escape sequence \\c\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "#BERT\n",
    "from flask import Flask, request, jsonify\n",
    "from bert import QA\n",
    "import torch\n",
    "import torch_npu\n",
    "from torch_npu.contrib import transfer_to_npu\n",
    "app = Flask(__name__)\n",
    "\n",
    "model = QA('/home/ma-user/work/Bert/model')\n",
    "##\n",
    "doc=\"Victoria has a written constitution enacted in 1975, but based on the 1855 colonial constitution, passed by the United Kingdom Parliament as the Victoria Constitution Act 1855, which establishes the Parliament as the state's law-making body for matters coming under state responsibility. The Victorian Constitution can be amended by the Parliament of Victoria, except for certain 'entrenched' provisions that require either an absolute majority in both houses, a three-fifths majority in both houses, or the approval of the Victorian people in a referendum, depending on the provision.\"\n",
    "q=\"When was the Victorian Constitution enacted?\"#1975\n",
    "# q=\"What does the Victorian Constitution establish?\"#the Parliament as the state's law-making body\n",
    "# ##\n",
    "\n",
    "# doc=\"xioaming is fat\"\n",
    "# q='what should xiaoming do'\n",
    "\n",
    "# q='How\\'s the weather today'\n",
    "\n",
    "# q='Where did I go today'\n",
    "\n",
    "#letting go of the pasd to the new possibilities that lie ahead\n",
    "# answer = model.predict(doc,q)\n",
    "\n",
    "# print(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "548130c6-a08c-45a4-bd46-71dc798b70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc=\"Artificial Intelligence (AI) has become one of the defining technologies of the 21st century, reshaping industries and daily life in ways previously unimaginable. From self-driving cars to personalized healthcare solutions, AI is transforming how we live, work, and interact with technology.\"\n",
    "# q='What is this article mainly about?'\n",
    "# answer = model.predict(doc,q)\n",
    "# print(answer['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a322b9-01dd-4830-affc-2cc594ca4469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5001\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [20/Sep/2024 17:02:57] \"POST /receive-texts HTTP/1.1\" 200 -\n",
      "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0xffff7c094820>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "127.0.0.1 - - [20/Sep/2024 17:17:55] \"POST /receive-texts HTTP/1.1\" 200 -\n",
      "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0xffff4f0c2ca0>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "127.0.0.1 - - [20/Sep/2024 17:27:11] \"POST /receive-texts HTTP/1.1\" 200 -\n",
      "sys:1: ResourceWarning: Unclosed socket <zmq.Socket(zmq.PUSH) at 0xffff4f0c2580>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# 接收 POST 请求中的文字数据\n",
    "@app.route('/receive-texts', methods=['POST'])\n",
    "def receive_data():\n",
    "    # 获取请求体中的 JSON 数据\n",
    "    data = request.get_json()\n",
    "    \n",
    "    # 检查是否有文字传入\n",
    "    # if 'text' not in data:\n",
    "    #     return jsonify({'error': 'No text provided'}), 400\n",
    "    \n",
    "    # 获取传入的文字\n",
    "    doc = data.get('text1', '')\n",
    "    q = data.get('text2', '')\n",
    "    # combined_text = f\"Combined Text: {text1} {text2}\"\n",
    "    answer = model.predict(doc,q)\n",
    "    \n",
    "    # 返回处理后的结果\n",
    "    return jsonify({\n",
    "        'answer': answer['answer']\n",
    "    })\n",
    "    # received_text = data['text']\n",
    "    \n",
    "    # 你可以在这里对接收到的文字进行处理\n",
    "    # processed_text = received_text.upper()  # 简单处理：将文字转换为大写\n",
    "    \n",
    "    # 返回处理后的文字作为响应\n",
    "    # return jsonify({'processed_text': processed_text})\n",
    "\n",
    "# 发送数据的接口\n",
    "@app.route('/send', methods=['GET'])\n",
    "def send_data():\n",
    "    # 这里模拟生成一个文字内容，可以替换为实际的数据处理结果\n",
    "    text_to_send = \"This is the text to send.\"\n",
    "\n",
    "    # 发送 JSON 响应\n",
    "    return jsonify({'text': text_to_send})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, use_reloader=False,port=5001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53877131-4105-4c90-9a9a-81435267e5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
